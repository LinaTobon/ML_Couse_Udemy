{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arboles y bosques aleatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "es una estructura de datos que se puede utilizar para establecer un conjunto de reglas de decision.\n",
    "\n",
    "Esta conformado por:\n",
    "* Nodos: puntos a partir del los cuales van saliendo las ramas, donde se va ramificando\n",
    "* Nodo raiz: punto desde donde se origina el arbol\n",
    "* Nodo hoja: ninguna rama se desprende del nodo\n",
    "* A excepcion del nodo terminal , todos los nodos representan una úncia variable y cada una de las ramas representan las posibles categorias (valores que puede tomar la variable)\n",
    "* Nodo terminal: decision final del algoritmo, valor que va a devolver al final de la ejecución\n",
    "* Ramas\n",
    "* Hojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Homogeneidad: intenta identificar una variable y establecer una clasificación dependiendo de una serie de valores, para dar al final una distribución lo mas homogenea posible en lo que se tata de referenciarse a la variable objetivo.\n",
    "una distribución homogenea significa que valores similares de la variable objetivo tienen que ser agrupados conjuntamente, de modo que una decision concreta pueda ser llevada a cabo.\n",
    "\n",
    "** Identificar una variable que resulte lo mas homogenea posible en la  clasificacion (entría y ganancia/perdida de la informacion, indice de Gini,reduccion de la varianza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Entropia: utiliza la teoria de la informacion. La premisa es que como mas homogeneo o mas puros son los nodos de un abol, se requiere menos informacion para representarlos. es la heterogeneidad de un nodo\n",
    "desde la teoria de la informacion, es el numero minimo de bits que hacen falta para codificar una determinada clasificacion de un miembro arbitario de un conjunto fijado a priori.\n",
    "cualquier reduccion de una entropia de un modo no deseable se medira como una ganancia de informacion. en el caso de un arbol de decision, los nodos que cuando los añadimos como resultado resultan en mayor ganancia de informacion del arbol global, se añade a la configuración.\n",
    "\n",
    "\n",
    "H(S) = \\sum -p{i}log_{2}(p{i})\n",
    "(suma de las probabiliddaes de todos los valores que puede tomar la variable objetivo, la entropia siempre es positiva porque el logaritmo en base 2 de un numero mas pequeño que 2 es negativo )\n",
    "\n",
    "* la entropia es cero cuando todas las observaciones fueron perfectamente homogeneas\n",
    "* toma su maximo(logaritmo en base 2 de l numero de categorias) cuando las observaciones son heterogeneas, cuando todos los pi son iguales"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
